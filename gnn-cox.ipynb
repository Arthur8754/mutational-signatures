{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Survival analysis with GNN and Cox Model\n",
    "In this notebook, we implement the whole pipeline to make survival analysis with Cox Model and GNN."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline description\n",
    "\n",
    "0. [Reading dataset, drop censored patients, and label patients](#0-reading-dataset-and-drop-censored-patients)\n",
    "1. [Training process](#1-training-process)\n",
    "    1. [Build the graph](#1-build-the-graph)\n",
    "    2. [Train the GNN for binary survival classification](#2-train-gnn)\n",
    "    3. [Extract learnt patients embeddings](#3-extract-learnt-patients-embeddings)\n",
    "    4. [Train the Cox Model with new patients embeddings](#4-train-cox-model-with-new-embeddings)\n",
    "2. [Testing process](#1-testing-process)\n",
    "    1. [Add test patients to the graph](#1-add-test-patients-to-the-graph)\n",
    "    2. [Make the GNN embedding prediction](#2-make-gnn-prediction)\n",
    "    3. [Make the Cox Model prediction](#3-make-cox-model-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from models.BuildGraph import BuildGraph\n",
    "from models.GCNClassifier import GCNClassifier\n",
    "from manage.GCNTrainTestManager import GCNTrainTestManager\n",
    "from models.CoxModel import CoxModel\n",
    "from torch_geometric.utils import from_networkx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Reading dataset and drop censored patients\n",
    "We use the dataset from the following article : https://doi.org/10.1158/1078-0432.CCR-20-1163. We drop the non naive patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Anonymous ID</th>\n",
       "      <th>EGA ID</th>\n",
       "      <th>Tumour type</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Line of therapy</th>\n",
       "      <th>Immunotherapy regimen</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Reason for discontinuation</th>\n",
       "      <th>Best response</th>\n",
       "      <th>Age at advanced disease diagnosis</th>\n",
       "      <th>...</th>\n",
       "      <th>Alive_0</th>\n",
       "      <th>Time to progression (days)</th>\n",
       "      <th>Progression_1</th>\n",
       "      <th>Clinical benefit</th>\n",
       "      <th>CD8+ T cell score</th>\n",
       "      <th>Exome mut per mb</th>\n",
       "      <th>Genome mut per mb</th>\n",
       "      <th>CD274 expression</th>\n",
       "      <th>M1M2 expression</th>\n",
       "      <th>Lymph related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14891</td>\n",
       "      <td>EGAD00001001961</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>Nivolumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Progression</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>179</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.351869</td>\n",
       "      <td>11.095310</td>\n",
       "      <td>23.0729</td>\n",
       "      <td>4.1689</td>\n",
       "      <td>55.51575</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18624</td>\n",
       "      <td>EGAD00001002047</td>\n",
       "      <td>AECA</td>\n",
       "      <td>F</td>\n",
       "      <td>10</td>\n",
       "      <td>Nivolumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Progression</td>\n",
       "      <td>Stable disease</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.071464</td>\n",
       "      <td>3.876336</td>\n",
       "      <td>5.4552</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>9.32352</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21392</td>\n",
       "      <td>EGAD00001002544</td>\n",
       "      <td>OV</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>Monalizumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Progression</td>\n",
       "      <td>Physician assessed SD</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.040394</td>\n",
       "      <td>2.415688</td>\n",
       "      <td>4.1274</td>\n",
       "      <td>4.0377</td>\n",
       "      <td>50.12008</td>\n",
       "      <td>Lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21516</td>\n",
       "      <td>EGAD00001002546</td>\n",
       "      <td>SKCM</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Ipilimumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Death</td>\n",
       "      <td>Not evaluable</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>6.235845</td>\n",
       "      <td>11.4871</td>\n",
       "      <td>0.6006</td>\n",
       "      <td>1.58550</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22186</td>\n",
       "      <td>EGAD00001001966</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Atezolizumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Progression</td>\n",
       "      <td>Stable disease</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>4.606660</td>\n",
       "      <td>7.1503</td>\n",
       "      <td>1.8234</td>\n",
       "      <td>38.42695</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>39280</td>\n",
       "      <td>EGAD00001004933</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Pembrolizumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>Physician Assessed SD</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>401</td>\n",
       "      <td>0</td>\n",
       "      <td>DCB</td>\n",
       "      <td>0.695396</td>\n",
       "      <td>84.998501</td>\n",
       "      <td>96.4079</td>\n",
       "      <td>8.4768</td>\n",
       "      <td>86.62561</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>37899</td>\n",
       "      <td>EGAD00001005838</td>\n",
       "      <td>CHOL</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Nivolumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Death</td>\n",
       "      <td>Physician assessed PR</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.818233</td>\n",
       "      <td>2.247151</td>\n",
       "      <td>2.7416</td>\n",
       "      <td>11.2704</td>\n",
       "      <td>47.97376</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>37775</td>\n",
       "      <td>EGAD00001004934</td>\n",
       "      <td>HNSC</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Avelumab/OX40 agonist PF-04518600</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Progression</td>\n",
       "      <td>Stable disease</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>3.848247</td>\n",
       "      <td>5.8036</td>\n",
       "      <td>8.7136</td>\n",
       "      <td>5.13403</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>38313</td>\n",
       "      <td>EGAD00001005844</td>\n",
       "      <td>ACC</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Avelumab/Debio1143 (SMAC mimetic)</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Toxicity</td>\n",
       "      <td>Partial response</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.617878</td>\n",
       "      <td>7.7940</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.51364</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>38207</td>\n",
       "      <td>EGAD00001005850</td>\n",
       "      <td>LUNG</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Pembrolizumab</td>\n",
       "      <td>Naive</td>\n",
       "      <td>Progression</td>\n",
       "      <td>Physician assessed SD</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>NCB</td>\n",
       "      <td>0.110416</td>\n",
       "      <td>33.763449</td>\n",
       "      <td>53.2769</td>\n",
       "      <td>23.8818</td>\n",
       "      <td>11.22022</td>\n",
       "      <td>Non-lymph related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Anonymous ID           EGA ID Tumour type Sex Line of therapy   \n",
       "0          14891  EGAD00001001961        LUNG   F               8  \\\n",
       "1          18624  EGAD00001002047        AECA   F              10   \n",
       "2          21392  EGAD00001002544          OV   F               6   \n",
       "3          21516  EGAD00001002546        SKCM   F               3   \n",
       "4          22186  EGAD00001001966        LUNG   F               4   \n",
       "..           ...              ...         ...  ..             ...   \n",
       "92         39280  EGAD00001004933        LUNG   M               2   \n",
       "94         37899  EGAD00001005838        CHOL   F               2   \n",
       "95         37775  EGAD00001004934        HNSC   M               1   \n",
       "96         38313  EGAD00001005844         ACC   F               3   \n",
       "97         38207  EGAD00001005850        LUNG   F               1   \n",
       "\n",
       "                Immunotherapy regimen Cohort Reason for discontinuation   \n",
       "0                           Nivolumab  Naive                Progression  \\\n",
       "1                           Nivolumab  Naive                Progression   \n",
       "2                         Monalizumab  Naive                Progression   \n",
       "3                          Ipilimumab  Naive                      Death   \n",
       "4                        Atezolizumab  Naive                Progression   \n",
       "..                                ...    ...                        ...   \n",
       "92                      Pembrolizumab  Naive                   Toxicity   \n",
       "94                          Nivolumab  Naive                      Death   \n",
       "95  Avelumab/OX40 agonist PF-04518600  Naive                Progression   \n",
       "96  Avelumab/Debio1143 (SMAC mimetic)  Naive                   Toxicity   \n",
       "97                      Pembrolizumab  Naive                Progression   \n",
       "\n",
       "            Best response  Age at advanced disease diagnosis  ...  Alive_0   \n",
       "0                   Mixed                                 45  ...        1  \\\n",
       "1          Stable disease                                 47  ...        1   \n",
       "2   Physician assessed SD                                 57  ...        1   \n",
       "3           Not evaluable                                 29  ...        1   \n",
       "4          Stable disease                                 52  ...        1   \n",
       "..                    ...                                ...  ...      ...   \n",
       "92  Physician Assessed SD                                 60  ...        1   \n",
       "94  Physician assessed PR                                 38  ...        1   \n",
       "95         Stable disease                                 69  ...        1   \n",
       "96       Partial response                                 34  ...        1   \n",
       "97  Physician assessed SD                                 50  ...        0   \n",
       "\n",
       "    Time to progression (days)  Progression_1  Clinical benefit   \n",
       "0                          179              1               NCB  \\\n",
       "1                          148              1               NCB   \n",
       "2                           79              1               NCB   \n",
       "3                           11              0               NCB   \n",
       "4                           80              1               NCB   \n",
       "..                         ...            ...               ...   \n",
       "92                         401              0               DCB   \n",
       "94                          96              0               NCB   \n",
       "95                          69              1               NCB   \n",
       "96                          51              1               NCB   \n",
       "97                         104              1               NCB   \n",
       "\n",
       "   CD8+ T cell score  Exome mut per mb  Genome mut per mb  CD274 expression   \n",
       "0           0.351869         11.095310            23.0729            4.1689  \\\n",
       "1           0.071464          3.876336             5.4552            0.7910   \n",
       "2           0.040394          2.415688             4.1274            4.0377   \n",
       "3           0.052774          6.235845            11.4871            0.6006   \n",
       "4           0.009323          4.606660             7.1503            1.8234   \n",
       "..               ...               ...                ...               ...   \n",
       "92          0.695396         84.998501            96.4079            8.4768   \n",
       "94          0.818233          2.247151             2.7416           11.2704   \n",
       "95          0.018982          3.848247             5.8036            8.7136   \n",
       "96          0.000000          5.617878             7.7940            0.0688   \n",
       "97          0.110416         33.763449            53.2769           23.8818   \n",
       "\n",
       "    M1M2 expression      Lymph related  \n",
       "0          55.51575  Non-lymph related  \n",
       "1           9.32352  Non-lymph related  \n",
       "2          50.12008      Lymph related  \n",
       "3           1.58550  Non-lymph related  \n",
       "4          38.42695  Non-lymph related  \n",
       "..              ...                ...  \n",
       "92         86.62561  Non-lymph related  \n",
       "94         47.97376  Non-lymph related  \n",
       "95          5.13403  Non-lymph related  \n",
       "96          0.51364  Non-lymph related  \n",
       "97         11.22022  Non-lymph related  \n",
       "\n",
       "[82 rows x 21 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('data/Supplemental-table1.xlsx')\n",
    "\n",
    "# Delete non naive patients\n",
    "df = df.loc[df[\"Cohort\"] == \"Naive\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete censored patients\n",
    "In statistics, some patients can have non faithful metrics, because of leaving the study for example. In our context, we want to drop patients which have not experienced an event (status = 0) and where the time of event is less than a given time t (which represents the time when we look at). Indeed, it might represent a precocious leaving of the patient ; what happened between the time of leaving and the time t when we look at ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_censored_patients(df: pd.DataFrame, status_name: str, time_name: str, t: float)->pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Delete censored patients from the initial dataframe. A censored patient is a patient with status = 0 and time_event < t.\n",
    "\n",
    "    ### Parameters :\n",
    "    - df : the dataframe to update\n",
    "    - status_name : the name of the status event column in the dataframe\n",
    "    - time_name : the name of the time event column in the dataframe\n",
    "    - t : the time when we look at (threshold).\n",
    "\n",
    "    ### Returns :\n",
    "    The dataframe without censored patients.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get index of to drop patients\n",
    "    to_drop = df.index[np.where((df[status_name] == 0) & (df[time_name]<t))[0]]\n",
    "    print(f\"{to_drop.shape[0]} patients censored deleted\")\n",
    "\n",
    "    # Update dataframe\n",
    "    df_non_censored = df.drop(to_drop,axis=0)\n",
    "\n",
    "    return df_non_censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 patients censored deleted\n",
      "1 patients censored deleted\n"
     ]
    }
   ],
   "source": [
    "## TTP (Time To Progression)\n",
    "t_ttp = np.median(df[\"Time to progression (days)\"].to_numpy())\n",
    "df_ttp_non_censored = drop_censored_patients(df, \"Progression_1\", \"Time to progression (days)\", t_ttp)\n",
    "\n",
    "## OS (Overall survival)\n",
    "t_os = np.median(df[\"Overall survival (days)\"].to_numpy())\n",
    "df_os_non_censored = drop_censored_patients(df, \"Alive_0\", \"Overall survival (days)\", t_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label patients for future classification\n",
    "Now, we want to create a label column to split event occured patients and no event occured patients : \n",
    "- status = 1 and time < t : class 1 (the event occured)\n",
    "- status = 1 and time > t : class 0 (the event has not occured yet at the time when we look at. The event will occur later)\n",
    "- status = 0 and time > t : class 0 (the event has not occured at the time when we look at)\n",
    "- status = 0 and time < t : censored patients, we already dropped these patients.\n",
    "\n",
    "Because we already dropped censored patients, we can see that we just have to test if time < t. If yes, we label 1, otherwise, we label 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_patients(df: pd.DataFrame, time_name: str, t: float)->pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Create new column in dataframe with event label depending on status, time and t values.\n",
    "\n",
    "    ### Parameters :\n",
    "    - df : the dataframe to update\n",
    "    - status_name : the name of the status event column in the dataframe\n",
    "    - time_name : the name of the time event column in the dataframe\n",
    "    - t : the time when we look at (threshold).\n",
    "\n",
    "    ### Returns :\n",
    "    The dataframe with an extra label column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We test if time < t (1 if yes, 0 otherwise)\n",
    "    df[\"event_occured\"] = np.where(df[time_name]<t, 1, 0)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TTP :\n",
    "df_ttp_non_censored = label_patients(df_ttp_non_censored, \"Time to progression (days)\",t_ttp)\n",
    "\n",
    "## OS :\n",
    "df_os_non_censored = label_patients(df_os_non_censored, \"Overall survival (days)\",t_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave one out cross validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "\n",
    "\n",
    "def leave_one_out_cross_validation(df: pd.DataFrame, column_name: str, features_name: list[str], label_name: str, n_epoch: int):\n",
    "    \"\"\" \n",
    "    Make the leave one out cross validation to train-test GNN+Cox model pipeline.\n",
    "\n",
    "    ### Parameters :\n",
    "    - df : the dataframe.\n",
    "    - column_name : the name of the column used to choose graph connections.\n",
    "    - features_name : the name of the features for each patient\n",
    "    - label_name : the name of the label for each patient\n",
    "    - n_epoch : the number of epochs for GNN training.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split dataframe in n_samples groups\n",
    "    n_samples = df.shape[0]\n",
    "    folds = KFold(n_splits=n_samples, shuffle=True).split(df)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(folds):\n",
    "\n",
    "        # Select train set and test set\n",
    "        df_train, df_test = df.iloc[train_index,:], df.iloc[test_index,:]\n",
    "\n",
    "        ### TRAIN ###\n",
    "\n",
    "        ## Build graph ##\n",
    "\n",
    "        # Instanciate graph builder\n",
    "        build_graph_train = BuildGraph(df_train)\n",
    "\n",
    "        # Compute adjacency matrix\n",
    "        build_graph_train.compute_adjacency_matrix(column_name)\n",
    "\n",
    "        # Create graph\n",
    "        build_graph_train.create_graph(features_name, label_name)\n",
    "\n",
    "        # Convert graph to PyTorch geometric format\n",
    "        pyg_graph_train = from_networkx(build_graph_train.G)\n",
    "\n",
    "        ## Train the GNN classifier ##\n",
    "\n",
    "        # Instanciate the GNN classifier\n",
    "        gcn_classifier = GCNClassifier(len(features_name))\n",
    "\n",
    "        # Instanciate the train manager, with loss and optimizer\n",
    "        loss_gnn = torch.nn.BCELoss()\n",
    "        optimizer_gnn = torch.optim.Adam(gcn_classifier.parameters(),lr=0.01)\n",
    "        train_manager = GCNTrainTestManager(gcn_classifier, pyg_graph_train, loss_gnn, optimizer_gnn)\n",
    "\n",
    "        # Training on num_epoch\n",
    "        train_manager.train(n_epoch)\n",
    "\n",
    "        # Extract new embeddings\n",
    "        df_learnt = pd.DataFrame(gcn_classifier.forward_conv(pyg_graph_train.x, pyg_graph_train.edge_index).detach().numpy(), columns=features_name, index=df_train.index)\n",
    "\n",
    "        ## Train the Cox Model ##\n",
    "\n",
    "        # Preprocessing data\n",
    "        X_train = df_learnt.to_numpy()\n",
    "        y_train = np.array(list((df_train[['Progression_1','Time to progression (days)']].itertuples(index=False, name=None))),dtype=[('Progression_1', '?'), ('Time to progression (days)', '<f8')])\n",
    "\n",
    "        # Instanciate Cox Model\n",
    "        cox_model = CoxModel()\n",
    "\n",
    "        # Training \n",
    "        cox_model.train(X_train, y_train)\n",
    "\n",
    "        # Find risk score cutoff between high risk and low risk\n",
    "        risk_scores_train = cox_model.predict_risk_score(X_train)\n",
    "        risk_cutoff = cox_model.find_cutoff(risk_scores_train)\n",
    "\n",
    "        ### TEST ###\n",
    "\n",
    "        ## Build graph ##\n",
    "\n",
    "        # Instanciate graph builder\n",
    "        build_graph_test = BuildGraph(pd.concat([df_train, df_test]))\n",
    "\n",
    "        # Compute adjacency matrix\n",
    "        build_graph_test.compute_adjacency_matrix(column_name)\n",
    "\n",
    "        # Create graph\n",
    "        build_graph_test.create_graph(features_name, label_name)\n",
    "\n",
    "        # Convert graph to PyTorch geometric format\n",
    "        pyg_graph_test = from_networkx(build_graph_test.G)\n",
    "\n",
    "        ## GNN embedding prediction ##\n",
    "\n",
    "        # Predict new embedding of test set\n",
    "        new_test_embedding = pd.DataFrame(gcn_classifier.forward_conv(pyg_graph_test.x, pyg_graph_test.edge_index).detach().numpy()[-1:], columns=features_name, index=df_test.index)\n",
    "\n",
    "        ## Cox Model prediction ##\n",
    "\n",
    "        # Preprocessing data\n",
    "        X_test = new_test_embedding.to_numpy()\n",
    "\n",
    "        # Predict risk score\n",
    "        risk_score_test = cox_model.predict_risk_score(X_test)\n",
    "        risk_class_test = cox_model.predict_class(risk_score_test, risk_cutoff)\n",
    "        print(f\"Test risk class : {risk_class_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = [\"CD8+ T cell score\",\"Exome mut per mb\"]\n",
    "label_name = \"event_occured\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [0.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n",
      "Epoch 1 of 100\n",
      "Epoch 11 of 100\n",
      "Epoch 21 of 100\n",
      "Epoch 31 of 100\n",
      "Epoch 41 of 100\n",
      "Epoch 51 of 100\n",
      "Epoch 61 of 100\n",
      "Epoch 71 of 100\n",
      "Epoch 81 of 100\n",
      "Epoch 91 of 100\n",
      "End of training.\n",
      "Test risk class : [1.]\n"
     ]
    }
   ],
   "source": [
    "## TTP :\n",
    "leave_one_out_cross_validation(df_ttp_non_censored, \"Tumour type\",features_name, label_name, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train-test patients\n",
    "We apply the leave one out cross validation, that is, we train on all patients except one, and we test on the last one. For the training, we build the graph, and apply the train. For the test, we add the patient to the graph, and we make a forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# df_ttp_non_censored_train = df_ttp_non_censored.iloc[:-1,:]\n",
    "# df_ttp_non_censored_test = df_ttp_non_censored_train.iloc[[-1],:]\n",
    "\n",
    "# ## OS :\n",
    "# df_os_non_censored_train = df_os_non_censored.iloc[:-1,:]\n",
    "# df_os_non_censored_test = df_os_non_censored_train.iloc[[-1],:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Build the graph to connect patients\n",
    "For now, we gather patients with the same tumour type, and, for each tumour type, all patients are inter-connected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate graph train builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# buildgraph_train_ttp = BuildGraph(df_ttp_non_censored_train)\n",
    "\n",
    "# ## OS :\n",
    "# buildgraph_train_os = BuildGraph(df_os_non_censored_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adjacency matrix\n",
    "If 2 patients have the same tumour type, we put 1 if the corresponding case in adjacency matrix. Otherwise, we put 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# buildgraph_train_ttp.compute_adjacency_matrix(\"Tumour type\")\n",
    "\n",
    "# ## OS :\n",
    "# buildgraph_train_os.compute_adjacency_matrix(\"Tumour type\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the graph from adjacency matrix\n",
    "Each node of the graph contains its features and its label. Then, with the adjacency matrix, we connect nodes. The resulting graph is under networkx format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Name of the features for each node\n",
    "# features_name = [\"CD8+ T cell score\",\"Exome mut per mb\"]\n",
    "\n",
    "# # Name of the label for each node\n",
    "# label_name = \"event_occured\"\n",
    "\n",
    "# ## TTP :\n",
    "# buildgraph_train_ttp.create_graph(features_name, label_name)\n",
    "\n",
    "# ## OS :\n",
    "# buildgraph_train_os.create_graph(features_name, label_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualize the graph\n",
    "Let's see what our graphs look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# buildgraph_train_ttp.show_graph(\"TTP graph\",\"ttp-graph.png\")\n",
    "\n",
    "# ## OS :\n",
    "# buildgraph_train_os.show_graph(\"OS graph\",\"os-graph.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the graph into PyTorch Geometric format\n",
    "For the following section, we need to convert the networkx graph to a PyTorch geometric one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TTP :\n",
    "pyg_graph_ttp = from_networkx(buildgraph_ttp.G)\n",
    "\n",
    "## OS :\n",
    "pyg_graph_os = from_networkx(buildgraph_os.G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Train the GNN for binary survival classification\n",
    "Now, we want to learn the patients embeddings. Because a library which learns the Cox parameters and GNN parameters does not exist, we need to split the process in 2 steps : first, learn the GNN parameters for the equivalent classification problem, and then, use the learnt embeddings to make the Cox regression. Here, we are at step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# gcn_classifier_ttp = GCNClassifier(num_features=len(features_name))\n",
    "\n",
    "# ## OS :\n",
    "# gcn_classifier_os = GCNClassifier(num_features=len(features_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training loss and optimizers, and instanciate train managers\n",
    "We use the Binary Cross Entropy Loss, and the Adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss :\n",
    "# loss_function_ttp = torch.nn.BCELoss()\n",
    "# loss_function_os = torch.nn.BCELoss()\n",
    "\n",
    "# # Optimizer :\n",
    "# optimizer_ttp = torch.optim.Adam(gcn_classifier_ttp.parameters(), lr=0.01)\n",
    "# optimizer_os = torch.optim.Adam(gcn_classifier_os.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP : \n",
    "# train_manager_ttp = GCNTrainTestManager(gcn_classifier_ttp, pyg_graph_ttp, loss_function_ttp, optimizer_ttp)\n",
    "\n",
    "# ## OS :\n",
    "# train_manager_os = GCNTrainTestManager(gcn_classifier_os, pyg_graph_os, loss_function_os, optimizer_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# train_manager_ttp.train(n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OS :\n",
    "# train_manager_os.train(n_epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# train_manager_ttp.plot_loss(\"Train loss TTP\",\"train-loss-ttp.png\")\n",
    "\n",
    "# ## OS :\n",
    "# train_manager_os.plot_loss(\"Train loss OS\",\"train-loss-os.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Extract learnt patients embeddings\n",
    "With the previous section, we learnt parameters of GCN classifier. So we can extract new patients embeddings, where each patient has its features and the features of its neighbours. For that, we apply the convolutive layer in our GCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP : \n",
    "# df_ttp_learnt = pd.DataFrame(gcn_classifier_ttp.forward_conv(pyg_graph_ttp.x, pyg_graph_ttp.edge_index).detach().numpy(), columns=features_name, index=df_ttp_non_censored_train.index)\n",
    "# print(\"Initial embeddings : \")\n",
    "# display(df_ttp_non_censored_train.loc[:,features_name])\n",
    "# print(\"New embeddings : \")\n",
    "# display(df_ttp_learnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OS : \n",
    "# df_os_learnt = pd.DataFrame(gcn_classifier_os.forward_conv(pyg_graph_os.x, pyg_graph_os.edge_index).detach().numpy(), columns=features_name, index=df_os_non_censored_train.index)\n",
    "# print(\"Initial embeddings : \")\n",
    "# display(df_os_non_censored_train.loc[:,features_name])\n",
    "# print(\"New embeddings : \")\n",
    "# display(df_os_learnt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Train Cox Model with new embeddings\n",
    "Now, we can integrate the new dataframe into a Cox Model. We use scikit survival, which implements a one layer perceptron Cox model. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data\n",
    "We need to format features into numpy array, and to format labels into list of tuples (status, time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# X_train_ttp = df_ttp_learnt.to_numpy()\n",
    "# y_train_ttp = np.array(list((df_ttp_non_censored_train[['Progression_1','Time to progression (days)']].itertuples(index=False, name=None))),dtype=[('Progression_1', '?'), ('Time to progression (days)', '<f8')])\n",
    "\n",
    "# ## OS :\n",
    "# X_train_os = df_os_learnt.to_numpy()\n",
    "# y_train_os = np.array(list((df_os_non_censored_train[['Alive_0','Overall survival (days)']].itertuples(index=False, name=None))),dtype=[('Alive_0', '?'), ('Overall survival (days)', '<f8')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate Cox model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# cox_model_ttp = CoxModel()\n",
    "\n",
    "# ## OS :\n",
    "# cox_model_os = CoxModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# cox_model_ttp.train(X_train_ttp, y_train_ttp)\n",
    "\n",
    "# ## OS :\n",
    "# cox_model_os.train(X_train_os, y_train_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Testing process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Add test patient to the graph\n",
    "Here, we connect the test patients with all patients which have the same tumour type. So we instanciate a new graph builder with concatenating train-test dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Graph builder\n",
    "\n",
    "# ## TTP :\n",
    "# build_graph_test_ttp = BuildGraph(pd.concat([df_ttp_non_censored_train, df_ttp_non_censored_test]))\n",
    "\n",
    "# ## OS :\n",
    "# build_graph_test_os = BuildGraph(pd.concat([df_os_non_censored_train, df_os_non_censored_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Adjacency matrix\n",
    "\n",
    "# ## TTP :\n",
    "# build_graph_test_ttp.compute_adjacency_matrix(\"Tumour type\")\n",
    "\n",
    "# ## OS :\n",
    "# build_graph_test_os.compute_adjacency_matrix(\"Tumour type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build graph\n",
    "\n",
    "# ## TTP :\n",
    "# build_graph_test_ttp.create_graph(features_name, label_name)\n",
    "\n",
    "# ## OS :\n",
    "# build_graph_test_os.create_graph(features_name, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show graph\n",
    "\n",
    "# ## TTP :\n",
    "# build_graph_test_ttp.show_graph(\"Test graph TTP\", \"test-graph-ttp.png\")\n",
    "\n",
    "# ## OS :\n",
    "# build_graph_test_os.show_graph(\"Test graph OS\", \"test-graph-os.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Networkx format --> PyTorch geometric format\n",
    "\n",
    "# ## TTP :\n",
    "# pyg_graph_test_ttp = from_networkx(build_graph_test_ttp.G)\n",
    "\n",
    "# ## OS :\n",
    "# pyg_graph_test_os = from_networkx(build_graph_test_os.G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 GNN embedding prediction for test patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# new_test_embedding_ttp = pd.DataFrame(gcn_classifier_ttp.forward_conv(pyg_graph_test_ttp.x, pyg_graph_test_ttp.edge_index).detach().numpy()[-1:],columns=features_name, index=df_ttp_non_censored_test.index)\n",
    "# print(\"Initial embeddings : \")\n",
    "# display(df_ttp_non_censored_test.loc[:,features_name])\n",
    "# print(\"New embeddings : \")\n",
    "# display(new_test_embedding_ttp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## OS :\n",
    "# new_test_embedding_os = pd.DataFrame(gcn_classifier_os.forward_conv(pyg_graph_test_os.x, pyg_graph_test_os.edge_index).detach().numpy()[-1:],columns=features_name, index=df_os_non_censored_test.index)\n",
    "# print(\"Initial embeddings : \")\n",
    "# display(df_os_non_censored_test.loc[:,features_name])\n",
    "# print(\"New embeddings : \")\n",
    "# display(new_test_embedding_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Make the Cox Model prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# X_test_ttp = new_test_embedding_ttp.to_numpy()\n",
    "# # y_test_ttp = np.array(list((df_ttp_non_censored_test[['Progression_1','Time to progression (days)']].itertuples(index=False, name=None))),dtype=[('Progression_1', '?'), ('Time to progression (days)', '<f8')])\n",
    "\n",
    "# ## OS :\n",
    "# X_test_os = new_test_embedding_os.to_numpy()\n",
    "# # y_test_os = np.array(list((df_os_non_censored_test[['Alive_0','Overall survival (days)']].itertuples(index=False, name=None))),dtype=[('Alive_0', '?'), ('Overall survival (days)', '<f8')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk score prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# risk_score_ttp = cox_model_ttp.predict_risk_score(X_test_ttp)\n",
    "# print(risk_score_ttp)\n",
    "\n",
    "# ## OS :\n",
    "# risk_score_os = cox_model_os.predict_risk_score(X_test_os)\n",
    "# print(risk_score_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find risk class for each patient\n",
    "First, we want to estimate the risk score of each patient, with the training of the Cox model. Next, we want to split patients in 2 groups : low risk and high risk (threshold = median risk). Then, we compare the 2 survival curves. It gives a measure of separation ability of our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# risk_classes_ttp, risk_scores_ttp = cox_model_ttp.leave_one_out_cross_validation(X_ttp,y_ttp)\n",
    "# print(\"TTP :\")\n",
    "# print(f\"n_samples high risk : {np.where(risk_classes_ttp==1)[0].shape[0]}\")\n",
    "# print(f\"n_samples low risk : {np.where(risk_classes_ttp==0)[0].shape[0]}\")\n",
    "\n",
    "# ## OS :\n",
    "# risk_classes_os, risk_scores_os = cox_model_os.leave_one_out_cross_validation(X_os,y_os)\n",
    "# print(\"OS :\")\n",
    "# print(f\"n_samples high risk : {np.where(risk_classes_os==1)[0].shape[0]}\")\n",
    "# print(f\"n_samples low risk : {np.where(risk_classes_os==0)[0].shape[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate survival function for each risk class\n",
    "We use the Kaplan Meier estimator to estimate the survival probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# status_ttp, time_ttp = df_ttp_non_censored_train['Progression_1'].to_numpy().astype(bool), df_ttp_non_censored_train['Time to progression (days)'].to_numpy()\n",
    "# # Low risk class\n",
    "# status_low_ttp, time_low_ttp = status_ttp[np.where(risk_classes_ttp==0)], time_ttp[np.where(risk_classes_ttp==0)]\n",
    "# time_axis_low_ttp, prob_axis_low_ttp = cox_model_ttp.kaplan_meier_estimation(status_low_ttp, time_low_ttp)\n",
    "# # High risk class\n",
    "# status_high_ttp, time_high_ttp = status_ttp[np.where(risk_classes_ttp==1)], time_ttp[np.where(risk_classes_ttp==1)]\n",
    "# time_axis_high_ttp, prob_axis_high_ttp = cox_model_ttp.kaplan_meier_estimation(status_high_ttp, time_high_ttp)\n",
    "\n",
    "# ## OS :\n",
    "# status_os, time_os = df_os_non_censored_train['Alive_0'].to_numpy().astype(bool), df_os_non_censored['Overall survival (days)'].to_numpy()\n",
    "# # Low risk class\n",
    "# status_low_os, time_low_os = status_os[np.where(risk_classes_os==0)], time_os[np.where(risk_classes_os==0)]\n",
    "# time_axis_low_os, prob_axis_low_os = cox_model_os.kaplan_meier_estimation(status_low_os, time_low_os)\n",
    "# # High risk class\n",
    "# status_high_os, time_high_os = status_os[np.where(risk_classes_os==1)], time_os[np.where(risk_classes_os==1)]\n",
    "# time_axis_high_os, prob_axis_high_os = cox_model_os.kaplan_meier_estimation(status_high_os, time_high_os)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate C index :\n",
    "In this context, the concordance index measures the proportion of patients comparable pairs in which the risk score and the surviving time are concordant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP : \n",
    "# c_index_ttp = cox_model_ttp.get_c_index(status_ttp, time_ttp, risk_scores_ttp)\n",
    "# print(f\"C index (TTP) : {c_index_ttp}\")\n",
    "\n",
    "# ## OS :\n",
    "# c_index_os = cox_model_os.get_c_index(status_os, time_os, risk_scores_os)\n",
    "# print(f\"C index (OS) : {c_index_os}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate log rank test p value\n",
    "The log rank test compares 2 survival curves. If the p value is low (under 5%), the 2 curves are different. Otherwise, the 2 curves are pretty similar. We make this test for the low risk (class 0) and high risk curves (class 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## TTP :\n",
    "# p_value_ttp = cox_model_ttp.log_rank_test(status_ttp.astype(int), time_ttp, risk_classes_ttp)\n",
    "# print(f\"p value (TTP) : {p_value_ttp}\")\n",
    "\n",
    "# ## OS :\n",
    "# p_value_os = cox_model_os.log_rank_test(status_os.astype(int), time_os, risk_classes_os)\n",
    "# print(f\"p value (OS) : {p_value_os}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot survival curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1,2,figsize=(15,7))\n",
    "# ax[0].step(time_axis_low_ttp, prob_axis_low_ttp, where='post',color='green',label='low risk')\n",
    "# ax[0].step(time_axis_high_ttp, prob_axis_high_ttp, where='post',color='red',label='high risk')\n",
    "# ax[0].set_xlabel('Time (days)')\n",
    "# ax[0].set_ylabel('No progression probability')\n",
    "# ax[0].set_title('No progression probability along time (TTP)')\n",
    "# ax[0].text(0,0.1,f'C-index : {c_index_ttp}')\n",
    "# ax[0].text(0,0.05,f'p value : {p_value_ttp}')\n",
    "\n",
    "# ax[1].step(time_axis_low_os, prob_axis_low_os, where='post',color='green',label='low risk')\n",
    "# ax[1].step(time_axis_high_os, prob_axis_high_os, where='post',color='red',label='high risk')\n",
    "# ax[1].set_xlabel('Time (days)')\n",
    "# ax[1].set_ylabel('Survival probability')\n",
    "# ax[1].set_title('Survival probability along time (OS)')\n",
    "# ax[1].text(0,0.1,f'C-index : {c_index_os}')\n",
    "# ax[1].text(0,0.05,f'p value : {p_value_os}')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig('gnn-survival-curves.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
